{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMilL5CEro0UPm460RFmxez",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/21JN1A4528/CODSOFT/blob/main/IMAGE_CAPTIONING.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "# Sample data (you should replace this with your dataset)\n",
        "captions = [\n",
        "    \"a black cat is sitting on a white table\",\n",
        "    \"a white dog is running in the grass\",\n",
        "    \"a group of people are playing soccer\"\n",
        "]\n",
        "\n",
        "# Define a vocabulary based on your dataset (or use a larger pre-trained vocabulary)\n",
        "vocab = Counter(word_tokenize(\" \".join(captions)))\n",
        "vocab = [word for word, freq in vocab.items() if freq > 1]  # Include words that appear more than once\n",
        "vocab.append(\"<start>\")\n",
        "vocab.append(\"<end>\")\n",
        "\n",
        "# Create word-to-index and index-to-word mappings\n",
        "word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
        "index_to_word = {idx: word for idx, word in enumerate(vocab)}\n",
        "\n",
        "# Define the image encoder (using pre-trained ResNet)\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ImageEncoder, self).__init__()\n",
        "        self.resnet = models.resnet50(pretrained=True)\n",
        "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-2])\n",
        "\n",
        "    def forward(self, image):\n",
        "        features = self.resnet(image)\n",
        "        return features\n",
        "\n",
        "# Define the captioning model (using LSTM)\n",
        "class CaptioningModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
        "        super(CaptioningModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, features, captions):\n",
        "        captions = self.embedding(captions)\n",
        "        inputs = torch.cat((features.unsqueeze(1), captions), 1)\n",
        "        outputs, _ = self.lstm(inputs)\n",
        "        outputs = self.linear(outputs)\n",
        "        return outputs\n",
        "\n",
        "# Load the pre-trained models\n",
        "encoder = ImageEncoder()\n",
        "captioning_model = CaptioningModel(vocab_size=len(vocab), embed_size=256, hidden_size=512)\n",
        "\n",
        "# Define your loss function and optimizer\n",
        "\n",
        "# Training loop (you'll need to adapt this for your dataset)\n",
        "\n",
        "# Inference function to generate captions for images\n",
        "\n",
        "# Load an image, preprocess it, and generate a caption\n",
        "\n",
        "# Remember that this is a simplified example. You'll need to adapt it to your specific dataset and model architecture.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNMDPd4hU0mx",
        "outputId": "b7a84c22-f63d-4b42-bc6d-58cfbd42d0ef"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}